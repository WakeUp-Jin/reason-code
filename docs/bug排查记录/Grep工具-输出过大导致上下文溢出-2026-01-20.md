📐 主题：Grep 工具成功但后续 “Failed to get response from AI”（上下文溢出）排查记录
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

结论（先给结论）
------------------------------------------------------------
1) Grep 工具本身是成功的：ripgrep 策略返回了 656 条匹配。
2) 失败发生在“把工具输出写入 current_turn 上下文”之后：工具输出太大，
   直接把上下文 token 撑爆，下一次 LLM 调用在溢出检查处被拦截。
3) 需要对“工具输出进入上下文”做强制的压缩/截断（全局兜底），
   并对 Grep 返回结构做进一步限量/分页，避免把全部 matches 原样塞回。

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

1️⃣ 现象与复现
------------------------------------------------------------
【现象】
- 终端显示：
  - Grep (bun|Bun) 成功，Found 656 matches (strategy: ripgrep)
  - 随后：Failed to get response from AI

【复现特征】
- 搜索范围较大（例如用户主目录 /Users/xjk）
- pattern 较宽（例如 bun|Bun）
- 返回匹配条数较多，且每条匹配都携带 line 内容

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

2️⃣ 日志证据（证明“工具成功 + 上下文溢出”）
------------------------------------------------------------
日志文件：
- logs/core/core-2026-01-20_00-04-03.log

关键片段：
1) 工具成功并记录 raw output（体量极大）
- logs/core/core-2026-01-20_00-04-03.log:98-101（节选）
  - ✅ [Search] Grep completed {"strategy":"ripgrep","resultCount":656,"duration":951}
  - 📤 [Tool:RawOutput] Grep {"size":580611,"tokens":145153,"output":"{... huge json ...}"}
  - ✅ [Tool] Grep completed ...

2) 随后发生上下文溢出
- logs/core/core-2026-01-20_00-04-03.log:104
  - ❌ [Context:Overflow] {"currentTokens":147666,"limit":64000,"usagePercent":"230.7%"}

解读：
- 工具结果被完整写入到了上下文（current_turn），导致 token 直接超过 modelLimit。
- ExecutionEngine 在下一轮 LLM 调用前做 overflow 检查，命中后直接失败。

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

3️⃣ 根因分析（为什么会把 tool 输出撑爆上下文）
------------------------------------------------------------
核心原因：工具输出在进入上下文时没有被压缩/截断。

关键路径：
1) 工具执行完后，ExecutionEngine 会将 tool 结果作为 message 写入 current_turn
- packages/core/src/core/agent/execution/ExecutionEngine.ts:370-374
  for (const result of results) {
    const toolMessage = buildToolMessage(result);
    this.contextManager.addToCurrentTurn(toolMessage);
  }

2) buildToolMessage 在成功时使用 result.resultString（通常是 JSON.stringify 的完整结果）
- packages/core/src/core/agent/execution/ExecutionEngine.ts:79-92
  const content = result.success ? result.resultString! : ...
  return { role: 'tool', content, ... }

3) 本次 Grep 的 resultString 非常大（~580KB 字符串，估算 ~145k tokens）
   因此写入 current_turn 后，上下文 token 直接爆表。

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

4️⃣ 为什么“工具输出总结/压缩”没有生效
------------------------------------------------------------
系统里存在工具输出总结器（用于控制 tool message 大小）：
- packages/core/src/core/context/utils/ToolOutputSummarizer.ts:22

但从日志看，本次 Grep 没有出现 “🗜️ [Tool:Compressed] Grep” 的记录，
说明在本次执行路径里 summarizer 没有真正处理 tool 输出，
导致 buildToolMessage 接收到的仍然是完整的大 resultString。

（注：是否未注入 summarizer/是否被配置关闭，需要结合 ToolScheduler 的配置进一步确认。）

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

5️⃣ 修复方案（推荐优先级）
------------------------------------------------------------
方案 A（必做 / 全局兜底）：工具输出进入上下文前强制压缩/截断
【目标】
- 任意工具输出都不能把上下文撑爆（哪怕工具实现忘记做限制）。

【做法】
- 在 ToolScheduler 或 buildToolMessage 之前，对 resultString 做统一处理：
  - 超过阈值（例如 >2000 tokens 或 >100k chars）时：
    - 先截断，再总结（必要时调用 LLM 生成摘要）
    - 或至少做 quickTruncate（不依赖 LLM）
- 只把 “processedOutput（摘要/截断版）” 放入 tool message content。

方案 B（Grep 专项优化）：返回结构限量 / 分页
【目标】
- Grep 不直接返回全量 matches，而是：
  - 返回 count、strategy、按文件聚合的少量样本（例如前 50~200 条）
  - 提供 offset/limit 参数让上层按需继续拉取下一页

方案 C（最后保险丝）：ContextManager 对 tool 消息做硬截断
【目标】
- 即使上层忘记压缩，也不会触发 Context:Overflow。
【做法】
- 在 addToCurrentTurn / CurrentTurnContext.format 前，对 role=tool 的 content 做 maxTokens/maxChars 截断。

推荐落地顺序：
1) 先做方案 A（全局兜底），立刻消除 “上下文被撑爆导致无法继续” 的系统性风险
2) 再做方案 B（改善 Grep 结果可用性与交互体验）
3) 最后加方案 C 作为保险丝（防未来回归）

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

6️⃣ 验证方式（建议）
------------------------------------------------------------
1) 重跑 /Users/xjk + bun|Bun：
   - 预期：Grep 成功后不再出现 Context:Overflow
   - 预期：tool message content 显著变小（有摘要/截断提示）

2) 构造一个超大输出工具（或 Grep 返回更多 matches）：
   - 预期：工具输出会被截断/总结，不会再把 currentTokens 推到 modelLimit 以上

