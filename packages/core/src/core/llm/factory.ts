import { ILLMService, LLMConfig, UnifiedToolManager } from './types/index.js';
import { DeepSeekService } from './services/DeepSeekService.js';
import { extractApiKey, getBaseURL } from './utils/helpers.js';

/**
 * å…¬å…±å·¥å‚å‡½æ•°ï¼šåˆ›å»º LLM æœåŠ¡å®ä¾‹ï¼ˆæ”¯æŒå¯é€‰çš„å·¥å…·ç®¡ç†å™¨ï¼‰
 *
 * @param config - LLM é…ç½®ï¼ˆåŒ…æ‹¬ providerã€modelã€apiKey ç­‰ï¼‰
 * @param toolManager - å¯é€‰çš„å·¥å…·ç®¡ç†å™¨å®ä¾‹
 * @param eventManager - å¯é€‰çš„äº‹ä»¶ç®¡ç†å™¨å®ä¾‹
 * @returns Promise<ILLMService> å®ä¾‹
 *
 * @example
 * ```typescript
 * import { ToolManager } from '../tool/ToolManager.js';
 *
 * const toolManager = new ToolManager();
 * const service = await createLLMService(
 *   {
 *     provider: 'deepseek',
 *     model: 'deepseek-chat',
 *     apiKey: 'your-api-key',
 *     maxIterations: 10
 *   },
 *   toolManager
 * );
 *
 * // ä½¿ç”¨æœåŠ¡
 * const response = await service.complete(messages, tools);
 * ```
 */
export async function createLLMService(
  config: LLMConfig,
  toolManager?: UnifiedToolManager,
  eventManager?: any
): Promise<ILLMService> {
  // 1. åˆ›å»ºæœåŠ¡å®ä¾‹
  const service = await _createLLMService(config, toolManager);

  // 2. è®¾ç½®äº‹ä»¶ç®¡ç†å™¨ï¼ˆå¦‚æœæä¾›ä¸”æœåŠ¡æ”¯æŒï¼‰
  if (eventManager && typeof (service as any).setEventManager === 'function') {
    (service as any).setEventManager(eventManager);
  }

  return service;
}

/**
 * å†…éƒ¨å‡½æ•°ï¼šåˆ›å»º LLM æœåŠ¡å®ä¾‹
 */
async function _createLLMService(
  config: LLMConfig,
  toolManager?: UnifiedToolManager
): Promise<ILLMService> {
  // 1. æå–å’ŒéªŒè¯ API Key
  const apiKey = extractApiKey(config);

  // 2. è·å– Base URL
  const baseURL = getBaseURL(config);

  // 3. æ ¹æ® provider åˆ›å»ºæœåŠ¡
  switch (config.provider.toLowerCase()) {
    case 'deepseek': {
      // ä½¿ç”¨ ES åŠ¨æ€å¯¼å…¥ OpenAI SDK
      const { default: OpenAI } = await import('openai');
      const openai = new OpenAI({ apiKey, baseURL });

      return new DeepSeekService(
        openai,
        config.model || 'deepseek-chat',
        {
          baseURL,
          maxRetries: 3,
          toolManager,
          maxIterations: config.maxIterations || 5,
        }
      );
    }

    // ğŸŸ¡ å¯æ‰©å±•ï¼šå…¶ä»–æä¾›å•†
    // case 'openai':
    // case 'anthropic':
    // case 'qwen':
    // case 'siliconflow':
    // case 'openrouter':

    default:
      throw new Error(`Unsupported LLM provider: ${config.provider}`);
  }
}
