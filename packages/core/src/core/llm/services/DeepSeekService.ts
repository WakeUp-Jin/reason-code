import OpenAI from 'openai';
import {
  ILLMService,
  LLMResponse,
  LLMChatOptions,
  ImageData,
  ToolSet,
  UnifiedToolManager,
} from '../types/index.js';
import { logger } from '../../../utils/logger.js';
import { sleep } from '../utils/helpers.js';

/**
 * DeepSeek LLM æœåŠ¡
 * ä½¿ç”¨ OpenAI SDKï¼ˆDeepSeek å…¼å®¹ OpenAI APIï¼‰
 * 
 * æä¾›ä¸¤ç§ä½¿ç”¨æ–¹å¼ï¼š
 * 1. complete() - ä¸Šä¸‹æ–‡è¡¥å…¨ï¼ˆæ¨èï¼‰
 * 2. generate() - å†…ç½®å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆå¯é€‰ï¼‰
 */
export class DeepSeekService implements ILLMService {
  private client: OpenAI;
  private model: string;
  private maxRetries: number;
  private toolManager?: UnifiedToolManager;
  private maxIterations: number;

  constructor(
    openai: OpenAI,
    model: string,
    options?: {
      baseURL?: string;
      maxRetries?: number;
      toolManager?: UnifiedToolManager;
      maxIterations?: number;
    }
  ) {
    this.client = openai;
    this.model = model;
    this.maxRetries = options?.maxRetries || 3;
    this.toolManager = options?.toolManager;
    this.maxIterations = options?.maxIterations || 5;

    logger.debug(`åˆå§‹åŒ– DeepSeekService: model=${model}`);
  }

  /**
   * æ ¸å¿ƒæ–¹æ³•ï¼šä¸Šä¸‹æ–‡è¡¥å…¨
   * æ¥æ”¶æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡ï¼ˆæ¶ˆæ¯å†å²ï¼‰ï¼Œè¿”å›æ¨¡å‹å“åº”
   * @param messages - ä¸Šä¸‹æ–‡æ¶ˆæ¯åˆ—è¡¨
   * @param tools - å¯ç”¨çš„å·¥å…·å®šä¹‰åˆ—è¡¨
   * @param options - ç”Ÿæˆå‚æ•°ï¼ˆtemperature, maxTokens ç­‰ï¼‰
   * @returns æ¨¡å‹å“åº”ï¼ˆåŒ…å«å†…å®¹ã€å·¥å…·è°ƒç”¨ã€ä½¿ç”¨ç»Ÿè®¡ï¼‰
   */
  async complete(
    messages: any[],
    tools?: any[],
    options?: LLMChatOptions
  ): Promise<LLMResponse> {
    let attempt = 0;

    while (attempt < this.maxRetries) {
      attempt++;

      try {
        logger.debug(
          `è°ƒç”¨ DeepSeek API (å°è¯• ${attempt}/${this.maxRetries}): ${messages.length} æ¡æ¶ˆæ¯, ${tools?.length || 0} ä¸ªå·¥å…·`
        );

        const response = await this.client.chat.completions.create({
          model: this.model,
          messages,
          tools: tools && tools.length > 0 ? tools : undefined,
          tool_choice: options?.toolChoice,
          temperature: options?.temperature,
          max_tokens: options?.maxTokens,
          top_p: options?.topP,
          frequency_penalty: options?.frequencyPenalty,
          presence_penalty: options?.presencePenalty,
          stop: options?.stop,
          response_format: options?.responseFormat,
        });

        const message = response.choices[0]?.message;
        if (!message) {
          throw new Error('DeepSeek API è¿”å›ç©ºå“åº”');
        }

        const result: LLMResponse = {
          content: message.content || '',
          toolCalls: message.tool_calls as any,
          finishReason: response.choices[0]?.finish_reason,
          usage: response.usage
            ? {
                promptTokens: response.usage.prompt_tokens,
                completionTokens: response.usage.completion_tokens,
                totalTokens: response.usage.total_tokens,
              }
            : undefined,
        };

        logger.debug(
          `DeepSeek å“åº”: ${result.content.slice(0, 100)}${result.content.length > 100 ? '...' : ''}, å·¥å…·è°ƒç”¨: ${result.toolCalls?.length || 0}`
        );

        return result;
      } catch (error: any) {
        logger.error(
          `DeepSeek API è°ƒç”¨å¤±è´¥ (${attempt}/${this.maxRetries}): ${error.message}`
        );

        if (attempt >= this.maxRetries) {
          throw new Error(`DeepSeek API è°ƒç”¨å¤±è´¥: ${error.message}`);
        }

        // æŒ‡æ•°é€€é¿
        const delay = 500 * attempt;
        logger.debug(`ç­‰å¾… ${delay}ms åé‡è¯•...`);
        await sleep(delay);
      }
    }

    throw new Error('Unreachable');
  }

  /**
   * ç®€å•å¯¹è¯ï¼šæ— å·¥å…·ï¼Œå•æ¬¡è°ƒç”¨
   * @param userInput - ç”¨æˆ·è¾“å…¥
   * @param systemPrompt - å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
   */
  async simpleChat(userInput: string, systemPrompt?: string): Promise<string> {
    const messages: any[] = [];

    if (systemPrompt) {
      messages.push({ role: 'system', content: systemPrompt });
    }

    messages.push({ role: 'user', content: userInput });

    const response = await this.complete(messages);
    return response.content;
  }

  /**
   * è·å–é…ç½®ä¿¡æ¯
   */
  getConfig(): { provider: string; model: string } {
    return {
      provider: 'deepseek',
      model: this.model,
    };
  }

  /**
   * å®Œæ•´æ–¹æ³•ï¼šæ”¯æŒå·¥å…·è°ƒç”¨å¾ªç¯
   * éœ€è¦åœ¨æ„é€ æ—¶ä¼ å…¥ toolManager
   * @param userInput - ç”¨æˆ·è¾“å…¥
   * @param imageData - å¯é€‰çš„å›¾ç‰‡æ•°æ®
   * @param _stream - æ˜¯å¦æµå¼è¾“å‡ºï¼ˆæš‚æœªå®ç°ï¼‰
   */
  async generate(
    userInput: string,
    imageData?: ImageData,
    _stream?: boolean
  ): Promise<string> {
    if (!this.toolManager) {
      throw new Error(
        'generate() æ–¹æ³•éœ€è¦ toolManagerï¼Œè¯·åœ¨æ„é€ æ—¶ä¼ å…¥æˆ–ä½¿ç”¨ chat() æ–¹æ³•'
      );
    }

    // åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨
    const messages: any[] = [
      {
        role: 'system',
        content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„ AI åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚',
      },
    ];

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    const userMessage: any = { role: 'user', content: userInput };
    if (imageData) {
      userMessage.content = [
        { type: 'text', text: userInput },
        imageData.url
          ? { type: 'image_url', image_url: { url: imageData.url } }
          : {
              type: 'image_url',
              image_url: {
                url: `data:${imageData.mimeType || 'image/png'};base64,${imageData.base64}`,
              },
            },
      ];
    }
    messages.push(userMessage);

    // è·å–å¯ç”¨å·¥å…·
    const availableTools = await this.toolManager.getToolsForProvider(
      'deepseek'
    );

    // å·¥å…·è°ƒç”¨å¾ªç¯
    let iteration = 0;
    while (iteration < this.maxIterations) {
      iteration++;
      logger.debug(`å·¥å…·è°ƒç”¨è¿­ä»£: ${iteration}/${this.maxIterations}`);

      // è°ƒç”¨ LLM
      const response = await this.complete(messages, availableTools, {
        toolChoice: iteration === 1 ? 'auto' : undefined,
      });

      // æ— å·¥å…·è°ƒç”¨ï¼Œè¿”å›ç»“æœ
      if (!response.toolCalls || response.toolCalls.length === 0) {
        logger.debug('æ— å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆç»“æœ');
        return response.content;
      }

      // è®°å½•æ€è€ƒå†…å®¹
      if (response.content) {
        logger.info(`ğŸ’­ åŠ©æ‰‹æ€è€ƒ: ${response.content}`);
      }

      // æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ï¼‰
      messages.push({
        role: 'assistant',
        content: response.content || null,
        tool_calls: response.toolCalls,
      });

      // æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
      for (const toolCall of response.toolCalls) {
        if (toolCall.type !== 'function' || !toolCall.function) {
          continue;
        }

        logger.info(`ğŸ”§ ä½¿ç”¨å·¥å…·: ${toolCall.function.name}`);

        try {
          const args = JSON.parse(toolCall.function.arguments);
          const result = await this.toolManager.executeTool(
            toolCall.function.name,
            args
          );

          logger.info(`âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ: ${JSON.stringify(result).slice(0, 200)}`);

          // æ·»åŠ å·¥å…·æ‰§è¡Œç»“æœ
          messages.push({
            role: 'tool',
            tool_call_id: toolCall.id,
            content: JSON.stringify(result),
          });
        } catch (error: any) {
          logger.error(`âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: ${error.message}`);

          // æ·»åŠ é”™è¯¯ç»“æœ
          messages.push({
            role: 'tool',
            tool_call_id: toolCall.id,
            content: JSON.stringify({ error: error.message }),
          });
        }
      }
    }

    throw new Error(`è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° (${this.maxIterations})`);
  }

  /**
   * è·å–æ‰€æœ‰å¯ç”¨å·¥å…·
   */
  async getAllTools(): Promise<ToolSet> {
    if (!this.toolManager) {
      return {};
    }
    return this.toolManager.getAllTools();
  }

  /**
   * æµå¼å¯¹è¯ï¼ˆé¢„ç•™æ¥å£ï¼‰
   * TODO: å®ç°æµå¼å“åº”
   */
  async chatStream(
    messages: any[],
    tools?: any[],
    options?: LLMChatOptions
  ): Promise<AsyncIterable<LLMResponse>> {
    throw new Error('æµå¼å“åº”æš‚æœªå®ç°');
  }
}

